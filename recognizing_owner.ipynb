{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_save_owner_embedding():\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # Convert to RGB and detect faces\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(frame_rgb)\n",
    "        boxes, _ = mtcnn.detect(pil_img)\n",
    "        \n",
    "        if boxes is not None:\n",
    "            # Extract the face with the largest area (most likely the main subject)\n",
    "            areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in boxes]\n",
    "            largest_face_index = areas.index(max(areas))\n",
    "            largest_face = mtcnn.extract(pil_img, [boxes[largest_face_index]], None)\n",
    "            \n",
    "            # Save the embedding of the largest detected face\n",
    "            owner_embedding = resnet(largest_face).detach()\n",
    "            torch.save(owner_embedding, 'owner_embedding.pt')\n",
    "            \n",
    "            print(\"Owner's face embedding captured and saved.\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return owner_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107M/107M [05:00<00:00, 373kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owner's face embedding captured and saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0021,  0.0769,  0.0299,  0.0142, -0.0086,  0.0093,  0.0047,  0.0161,\n",
       "          0.0467, -0.0544,  0.0642, -0.0252,  0.0319,  0.0242, -0.0216, -0.0483,\n",
       "         -0.0527, -0.0005, -0.0003,  0.0345,  0.0481, -0.0669,  0.0050, -0.0214,\n",
       "          0.0328,  0.0082,  0.0270, -0.0053, -0.0034, -0.0353,  0.0330,  0.0362,\n",
       "         -0.0751,  0.0268,  0.0725,  0.0279, -0.0073,  0.0073, -0.0289,  0.0258,\n",
       "         -0.0248,  0.0031, -0.0645, -0.0327, -0.0332, -0.0751, -0.0350,  0.0339,\n",
       "          0.0595, -0.0430, -0.0728, -0.0725,  0.0206,  0.0622,  0.0904,  0.0462,\n",
       "         -0.0201,  0.0223,  0.0122, -0.0033,  0.0642, -0.0570,  0.0424,  0.0551,\n",
       "          0.0909, -0.0426, -0.0244, -0.0571,  0.0066, -0.0536, -0.1010, -0.0079,\n",
       "         -0.0637, -0.0327,  0.0964, -0.0487, -0.0153, -0.0088,  0.0632, -0.0170,\n",
       "         -0.0398, -0.0196, -0.0037, -0.0488, -0.0177,  0.0504,  0.0180, -0.0062,\n",
       "          0.0564,  0.0116,  0.0069,  0.0322, -0.0487, -0.0394, -0.0352,  0.0449,\n",
       "          0.0593, -0.0137,  0.0308,  0.0162, -0.0201, -0.0650, -0.0056, -0.0287,\n",
       "          0.0028,  0.0058, -0.0355,  0.0234, -0.0164,  0.0149,  0.0342,  0.0598,\n",
       "          0.0601,  0.0196, -0.0122,  0.0095, -0.0340,  0.0330, -0.1143, -0.0245,\n",
       "         -0.0604,  0.0257,  0.0187,  0.0770,  0.0101, -0.0262, -0.0035, -0.0727,\n",
       "         -0.0490,  0.0207, -0.0284, -0.0014,  0.0723, -0.0364,  0.1028,  0.0550,\n",
       "          0.0640,  0.0292, -0.0366, -0.0186,  0.0537, -0.0150, -0.0120,  0.0143,\n",
       "         -0.0488,  0.0651, -0.0336,  0.1327, -0.0243,  0.0209, -0.0090,  0.0462,\n",
       "         -0.0406, -0.0299, -0.0151,  0.0435,  0.0151,  0.0378, -0.0324,  0.0116,\n",
       "         -0.0135,  0.0397,  0.0509, -0.0082, -0.0813,  0.0011, -0.0135, -0.0012,\n",
       "          0.0211,  0.0447,  0.0274, -0.0432,  0.0779, -0.0193, -0.0123, -0.0384,\n",
       "         -0.1151, -0.0144, -0.0877,  0.0311,  0.0276,  0.0318,  0.0151, -0.0035,\n",
       "         -0.0064,  0.0206,  0.0047, -0.0114, -0.0160, -0.0231, -0.0768,  0.0693,\n",
       "          0.0004, -0.0458, -0.0993,  0.0368, -0.0198, -0.0600,  0.0785, -0.1151,\n",
       "          0.0033, -0.0216,  0.0009,  0.0370,  0.0738, -0.0612, -0.0721, -0.0355,\n",
       "          0.0113, -0.0083, -0.0351, -0.0603,  0.0427, -0.0521, -0.0225,  0.0426,\n",
       "          0.0503,  0.0111, -0.0010, -0.0312,  0.0048,  0.0426,  0.0261,  0.0347,\n",
       "          0.0639,  0.0815,  0.0211,  0.0217, -0.0231, -0.0572, -0.0151,  0.0666,\n",
       "         -0.0420, -0.0295,  0.0602,  0.0844, -0.0471,  0.0390,  0.0282,  0.0072,\n",
       "         -0.1019,  0.0427, -0.0384, -0.0015,  0.0004, -0.0092,  0.0007, -0.1163,\n",
       "          0.0482, -0.0105, -0.0224,  0.0007,  0.0176,  0.0382,  0.0515, -0.0159,\n",
       "         -0.0830,  0.0473, -0.0233,  0.0090,  0.0630,  0.0089,  0.0477,  0.0072,\n",
       "         -0.0249, -0.0698, -0.0222,  0.0397, -0.0456, -0.0506,  0.0267,  0.0363,\n",
       "         -0.0488,  0.0376,  0.0330,  0.0291,  0.0016, -0.0613,  0.0040,  0.0510,\n",
       "         -0.0303,  0.0075, -0.0697,  0.0661, -0.0190,  0.0330,  0.0229,  0.0118,\n",
       "         -0.0343,  0.0742,  0.0272,  0.0064,  0.0468,  0.0488,  0.0241,  0.0553,\n",
       "         -0.0202, -0.0287, -0.0177, -0.0200, -0.0440,  0.0872, -0.0176,  0.0494,\n",
       "         -0.0168, -0.0113,  0.0383,  0.0526, -0.0110, -0.0018, -0.0853, -0.0408,\n",
       "          0.0788, -0.0073,  0.0509,  0.0735,  0.0796, -0.0431, -0.0447, -0.0208,\n",
       "         -0.0637, -0.0080, -0.0308, -0.0069,  0.0166, -0.0130,  0.0060,  0.0264,\n",
       "         -0.0390,  0.0642,  0.0234,  0.0460, -0.0161, -0.0382, -0.0016,  0.0249,\n",
       "         -0.0062,  0.0855,  0.0088, -0.0148,  0.0313, -0.0670, -0.0131,  0.0119,\n",
       "          0.0161,  0.0179,  0.0070,  0.0623, -0.0679, -0.0314, -0.0624, -0.0128,\n",
       "          0.0652, -0.0175, -0.0129,  0.0268,  0.0499, -0.0343,  0.0321, -0.0010,\n",
       "          0.0008,  0.0199, -0.0138, -0.0339,  0.0048,  0.0166, -0.0255,  0.0111,\n",
       "          0.0013,  0.0374,  0.0173,  0.0505,  0.0379,  0.0403, -0.0785, -0.0285,\n",
       "          0.0704, -0.0073, -0.0173, -0.0272, -0.0253,  0.0372,  0.0864, -0.0616,\n",
       "          0.0452, -0.0663, -0.0076,  0.0061, -0.0175,  0.0853,  0.0040, -0.0005,\n",
       "          0.0065,  0.0384, -0.0405, -0.0205, -0.0151,  0.0355, -0.0400, -0.0222,\n",
       "         -0.0199, -0.0079,  0.0019, -0.0123,  0.0133,  0.0824, -0.0440,  0.0176,\n",
       "          0.0493,  0.0759, -0.0085,  0.0588, -0.0800, -0.0576, -0.0441, -0.0217,\n",
       "         -0.0223, -0.0587, -0.0326,  0.0066,  0.0644,  0.0054,  0.0069,  0.0295,\n",
       "          0.0561,  0.0406,  0.0159, -0.0757,  0.0311, -0.0188, -0.0215, -0.0183,\n",
       "          0.0643, -0.0413,  0.0192, -0.0098, -0.0491, -0.0683, -0.0361,  0.0214,\n",
       "          0.0448,  0.0449,  0.0008,  0.0291,  0.0522, -0.0071, -0.0372,  0.0155,\n",
       "         -0.0091,  0.0314,  0.0705, -0.1075,  0.0098,  0.0165,  0.0189,  0.0012,\n",
       "         -0.0085, -0.0115,  0.0931, -0.0749,  0.0254,  0.1274,  0.0189,  0.0134,\n",
       "         -0.0739,  0.0190,  0.0726, -0.0010, -0.0062, -0.0119, -0.1015, -0.0645,\n",
       "         -0.0233, -0.0067,  0.0887,  0.0399, -0.1133,  0.0215, -0.0026, -0.0911,\n",
       "          0.0191,  0.0556,  0.0038,  0.0371, -0.0201, -0.0526,  0.0941,  0.0239,\n",
       "         -0.0450, -0.0204, -0.0089,  0.0308, -0.0108,  0.0641,  0.0054,  0.0633,\n",
       "         -0.0449,  0.0251,  0.0157, -0.0311,  0.0350, -0.0060,  0.0211, -0.0930,\n",
       "         -0.0167, -0.0775, -0.0138, -0.0267,  0.0430, -0.0396, -0.0171,  0.1045]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture_and_save_owner_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_and_highlight():\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "    owner_embedding = torch.load('owner_embedding.pt')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(frame_rgb)\n",
    "\n",
    "            # Detect faces\n",
    "            boxes, _ = mtcnn.detect(pil_img)\n",
    "            draw = ImageDraw.Draw(pil_img)\n",
    "            if boxes is not None:\n",
    "                faces = mtcnn.extract(pil_img, boxes, None)\n",
    "                embeddings = resnet(faces).detach()\n",
    "\n",
    "                for i, box in enumerate(boxes):\n",
    "                    # Calculate distance to the owner's embedding\n",
    "                    distance = (embeddings[i] - owner_embedding).norm().item()\n",
    "                    if distance < 0.6:  # threshold for recognition, tune based on your dataset\n",
    "                        outline_color = (0, 255, 0)  # Green for owner\n",
    "                    else:\n",
    "                        outline_color = (255, 0, 0)  # Red for others\n",
    "\n",
    "                    draw.rectangle(box.tolist(), outline=outline_color, width=6)\n",
    "\n",
    "            # Display the image\n",
    "            cv_frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Webcam', cv_frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_and_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owner present: False\n"
     ]
    }
   ],
   "source": [
    "def is_owner_present():\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "    owner_embedding = torch.load('owner_embedding.pt')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    owner_detected = False  # Flag to indicate if the owner is detected\n",
    "\n",
    "    try:\n",
    "        # Capture a single frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(frame_rgb)\n",
    "\n",
    "            # Detect faces\n",
    "            boxes, _ = mtcnn.detect(pil_img)\n",
    "            if boxes is not None:\n",
    "                faces = mtcnn.extract(pil_img, boxes, None)\n",
    "                embeddings = resnet(faces).detach()\n",
    "\n",
    "                for embedding in embeddings:\n",
    "                    # Calculate distance to the owner's embedding\n",
    "                    distance = (embedding - owner_embedding).norm().item()\n",
    "                    if distance < 0.6:  # threshold for recognition, tune based on your dataset\n",
    "                        owner_detected = True\n",
    "                        break\n",
    "\n",
    "        # Optionally, display the frame with or without marking\n",
    "        # Comment out if not needed\n",
    "        cv_frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('Webcam', cv_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            pass\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return owner_detected\n",
    "\n",
    "# Example of using the function\n",
    "owner_present = is_owner_present()\n",
    "print(\"Owner present:\", owner_present)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
